---
title: "Breakout Activity"
format: pdf
editor: visual
---

```{python}
import pandas as pd

# 1. Loading the dataset
data = pd.read_csv('survey.csv')

# Quick overview of the dataset
print(data.head())
print(data.info())  # Check data types and for any missing values
print(data.describe())  # Get a statistical summary of the data
```

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Step 2: Load the dataset
data = pd.read_csv('survey.csv') 

# Let's assume the target variable is 'Weight' and the features are 'Height', 'Age', 'ExerciseLevel'
# Modify based on your dataset structure
features = ['Age', 'family_history', 'work_interfere', 'benefits', 'care_options', 'wellness_program']  # Replace with relevant feature names
target = 'treatment'  # Replace with the relevant target column

# Extracting features (X) and target (y)
X = data[features]
y = data[target]

# Handling categorical variables (optional)
# Convert categorical variables into numeric using one-hot encoding or label encoding if needed
X = pd.get_dummies(X, drop_first=True)

# Splitting the data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check if data was split correctly
print("Training set size:", X_train.shape)
print("Testing set size:", X_test.shape)
```

```{python}
data['treatment_numeric'] = np.where(data['treatment'] == 'Yes', 1, 0)
```

```{python}
features = ['Age', 'Gender', 'self_employed', 'family_history', 'work_interfere', 
            'no_employees', 'remote_work', 'tech_company', 'benefits', 
            'care_options', 'wellness_program', 'seek_help', 'anonymity']

```

```{python}
# Convert categorical variables to dummy variables
X = pd.get_dummies(data[features], drop_first=True)

```

```{python}
# Define target variable
y = data['treatment_numeric']  # Using our hypothetical target variable
```

```{python}
# Check for any missing values in features or target
X = X.fillna(0)  # Replace NaN values with 0 (or use other imputation strategies)
y = y.fillna(0)  # Ensure target does not contain NaNs

# Step 5: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

```{python}
# Step 6: Train a Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Step 7: Predict on the test set
y_pred = model.predict(X_test)

# Model evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse:.4f}")
print(f"RÂ² Score: {r2:.4f}")

# Step 8: Visualize the results
# Plotting the predicted vs actual values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='blue', alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)  # Diagonal line
plt.title('Actual vs Predicted Treatment Likelihood')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.grid()
plt.show()

# Residual plot
plt.figure(figsize=(10, 6))
sns.residplot(x=y_test, y=y_pred, lowess=True, color='purple')
plt.title('Residuals Plot')
plt.xlabel('Actual Values')
plt.ylabel('Residuals')
plt.axhline(0, color='red', linestyle='--')
plt.show()
```
